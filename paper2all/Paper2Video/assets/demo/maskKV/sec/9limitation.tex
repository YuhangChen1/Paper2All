\section{Limitations}
Our current experiments are limited to 7B/8B-scale dLLMs, constrained by the limited availability of open-source models.
The effectiveness of our proposed methods and the observed attention behavior patterns have yet to be validated on both larger-scale and smaller lightweight models.
Moreover, our evaluation is confined to text generation benchmarks, and extending the analysis to multimodal reasoning remains an important direction for future research.